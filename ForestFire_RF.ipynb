{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database.\n",
      "Tables in the database:\n",
      "spatial_ref_sys\n",
      "spatialite_history\n",
      "sqlite_sequence\n",
      "geometry_columns\n",
      "spatial_ref_sys_aux\n",
      "views_geometry_columns\n",
      "virts_geometry_columns\n",
      "geometry_columns_statistics\n",
      "views_geometry_columns_statistics\n",
      "virts_geometry_columns_statistics\n",
      "geometry_columns_field_infos\n",
      "views_geometry_columns_field_infos\n",
      "virts_geometry_columns_field_infos\n",
      "geometry_columns_time\n",
      "geometry_columns_auth\n",
      "views_geometry_columns_auth\n",
      "virts_geometry_columns_auth\n",
      "sql_statements_log\n",
      "SpatialIndex\n",
      "ElementaryGeometries\n",
      "KNN\n",
      "Fires\n",
      "idx_Fires_Shape\n",
      "idx_Fires_Shape_node\n",
      "idx_Fires_Shape_rowid\n",
      "idx_Fires_Shape_parent\n",
      "NWCG_UnitIDActive_20170109\n",
      "\n",
      "First few rows from the Fires table:\n",
      "   OBJECTID  FOD_ID      FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
      "0         1       1  FS-1418826                FED   FS-FIRESTAT   \n",
      "1         2       2  FS-1418827                FED   FS-FIRESTAT   \n",
      "2         3       3  FS-1418835                FED   FS-FIRESTAT   \n",
      "3         4       4  FS-1418845                FED   FS-FIRESTAT   \n",
      "4         5       5  FS-1418847                FED   FS-FIRESTAT   \n",
      "\n",
      "  NWCG_REPORTING_AGENCY NWCG_REPORTING_UNIT_ID  NWCG_REPORTING_UNIT_NAME  \\\n",
      "0                    FS                USCAPNF    Plumas National Forest   \n",
      "1                    FS                USCAENF  Eldorado National Forest   \n",
      "2                    FS                USCAENF  Eldorado National Forest   \n",
      "3                    FS                USCAENF  Eldorado National Forest   \n",
      "4                    FS                USCAENF  Eldorado National Forest   \n",
      "\n",
      "  SOURCE_REPORTING_UNIT SOURCE_REPORTING_UNIT_NAME  ... FIRE_SIZE_CLASS  \\\n",
      "0                  0511     Plumas National Forest  ...               A   \n",
      "1                  0503   Eldorado National Forest  ...               A   \n",
      "2                  0503   Eldorado National Forest  ...               A   \n",
      "3                  0503   Eldorado National Forest  ...               A   \n",
      "4                  0503   Eldorado National Forest  ...               A   \n",
      "\n",
      "    LATITUDE   LONGITUDE OWNER_CODE       OWNER_DESCR STATE COUNTY FIPS_CODE  \\\n",
      "0  40.036944 -121.005833        5.0              USFS    CA     63       063   \n",
      "1  38.933056 -120.404444        5.0              USFS    CA     61       061   \n",
      "2  38.984167 -120.735556       13.0  STATE OR PRIVATE    CA     17       017   \n",
      "3  38.559167 -119.913333        5.0              USFS    CA      3       003   \n",
      "4  38.559167 -119.933056        5.0              USFS    CA      3       003   \n",
      "\n",
      "   FIPS_NAME                                              Shape  \n",
      "0     Plumas  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xe8d\\xc2\\x92_@^\\xc0...  \n",
      "1     Placer  b'\\x00\\x01\\xad\\x10\\x00\\x00T\\xb6\\xeej\\xe2\\x19^\\...  \n",
      "2  El Dorado  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\xa5\\xa0W\\x13/^\\...  \n",
      "3     Alpine  b'\\x00\\x01\\xad\\x10\\x00\\x00\\x94\\xac\\xa3\\rt\\xfa]...  \n",
      "4     Alpine  b'\\x00\\x01\\xad\\x10\\x00\\x00@\\xe3\\xaa.\\xb7\\xfb]\\...  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "database_path = 'C:\\\\wildfire\\\\wildfire_detect\\\\FPA_FOD_20170508.sqlite'  # Use the correct path\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"Tables in the database:\")\n",
    "    for table in tables:\n",
    "        print(table[0])\n",
    "\n",
    "    table_name = 'Fires'  # Assuming 'Fires' is still the correct table\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT 5\"  # Limit to first 5 rows for a quick check\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    print(\"\\nFirst few rows from the Fires table:\")\n",
    "    print(df)\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Error connecting to or querying the database: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Database file not found at {database_path}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OBJECTID', 'FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n",
      "       'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID',\n",
      "       'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT',\n",
      "       'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID',\n",
      "       'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME',\n",
      "       'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME',\n",
      "       'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY',\n",
      "       'DISCOVERY_TIME', 'STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR', 'CONT_DATE',\n",
      "       'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE',\n",
      "       'LONGITUDE', 'OWNER_CODE', 'OWNER_DESCR', 'STATE', 'COUNTY',\n",
      "       'FIPS_CODE', 'FIPS_NAME', 'Shape'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database.\n",
      "\n",
      "First few rows from the Fires table (head):\n",
      "   OBJECTID  FOD_ID      FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
      "0         1       1  FS-1418826                FED   FS-FIRESTAT   \n",
      "1         2       2  FS-1418827                FED   FS-FIRESTAT   \n",
      "2         3       3  FS-1418835                FED   FS-FIRESTAT   \n",
      "3         4       4  FS-1418845                FED   FS-FIRESTAT   \n",
      "4         5       5  FS-1418847                FED   FS-FIRESTAT   \n",
      "\n",
      "  NWCG_REPORTING_AGENCY NWCG_REPORTING_UNIT_ID  NWCG_REPORTING_UNIT_NAME  \\\n",
      "0                    FS                USCAPNF    Plumas National Forest   \n",
      "1                    FS                USCAENF  Eldorado National Forest   \n",
      "2                    FS                USCAENF  Eldorado National Forest   \n",
      "3                    FS                USCAENF  Eldorado National Forest   \n",
      "4                    FS                USCAENF  Eldorado National Forest   \n",
      "\n",
      "  SOURCE_REPORTING_UNIT SOURCE_REPORTING_UNIT_NAME  ... FIRE_SIZE_CLASS  \\\n",
      "0                  0511     Plumas National Forest  ...               A   \n",
      "1                  0503   Eldorado National Forest  ...               A   \n",
      "2                  0503   Eldorado National Forest  ...               A   \n",
      "3                  0503   Eldorado National Forest  ...               A   \n",
      "4                  0503   Eldorado National Forest  ...               A   \n",
      "\n",
      "    LATITUDE   LONGITUDE OWNER_CODE       OWNER_DESCR STATE COUNTY FIPS_CODE  \\\n",
      "0  40.036944 -121.005833        5.0              USFS    CA     63       063   \n",
      "1  38.933056 -120.404444        5.0              USFS    CA     61       061   \n",
      "2  38.984167 -120.735556       13.0  STATE OR PRIVATE    CA     17       017   \n",
      "3  38.559167 -119.913333        5.0              USFS    CA      3       003   \n",
      "4  38.559167 -119.933056        5.0              USFS    CA      3       003   \n",
      "\n",
      "   FIPS_NAME                                              Shape  \n",
      "0     Plumas  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xe8d\\xc2\\x92_@^\\xc0...  \n",
      "1     Placer  b'\\x00\\x01\\xad\\x10\\x00\\x00T\\xb6\\xeej\\xe2\\x19^\\...  \n",
      "2  El Dorado  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\xa5\\xa0W\\x13/^\\...  \n",
      "3     Alpine  b'\\x00\\x01\\xad\\x10\\x00\\x00\\x94\\xac\\xa3\\rt\\xfa]...  \n",
      "4     Alpine  b'\\x00\\x01\\xad\\x10\\x00\\x00@\\xe3\\xaa.\\xb7\\xfb]\\...  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "\n",
      "Information about the Fires table (info):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1880465 entries, 0 to 1880464\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   OBJECTID                    int64  \n",
      " 1   FOD_ID                      int64  \n",
      " 2   FPA_ID                      object \n",
      " 3   SOURCE_SYSTEM_TYPE          object \n",
      " 4   SOURCE_SYSTEM               object \n",
      " 5   NWCG_REPORTING_AGENCY       object \n",
      " 6   NWCG_REPORTING_UNIT_ID      object \n",
      " 7   NWCG_REPORTING_UNIT_NAME    object \n",
      " 8   SOURCE_REPORTING_UNIT       object \n",
      " 9   SOURCE_REPORTING_UNIT_NAME  object \n",
      " 10  LOCAL_FIRE_REPORT_ID        object \n",
      " 11  LOCAL_INCIDENT_ID           object \n",
      " 12  FIRE_CODE                   object \n",
      " 13  FIRE_NAME                   object \n",
      " 14  ICS_209_INCIDENT_NUMBER     object \n",
      " 15  ICS_209_NAME                object \n",
      " 16  MTBS_ID                     object \n",
      " 17  MTBS_FIRE_NAME              object \n",
      " 18  COMPLEX_NAME                object \n",
      " 19  FIRE_YEAR                   int64  \n",
      " 20  DISCOVERY_DATE              float64\n",
      " 21  DISCOVERY_DOY               int64  \n",
      " 22  DISCOVERY_TIME              object \n",
      " 23  STAT_CAUSE_CODE             float64\n",
      " 24  STAT_CAUSE_DESCR            object \n",
      " 25  CONT_DATE                   float64\n",
      " 26  CONT_DOY                    float64\n",
      " 27  CONT_TIME                   object \n",
      " 28  FIRE_SIZE                   float64\n",
      " 29  FIRE_SIZE_CLASS             object \n",
      " 30  LATITUDE                    float64\n",
      " 31  LONGITUDE                   float64\n",
      " 32  OWNER_CODE                  float64\n",
      " 33  OWNER_DESCR                 object \n",
      " 34  STATE                       object \n",
      " 35  COUNTY                      object \n",
      " 36  FIPS_CODE                   object \n",
      " 37  FIPS_NAME                   object \n",
      " 38  Shape                       object \n",
      "dtypes: float64(8), int64(4), object(27)\n",
      "memory usage: 559.5+ MB\n",
      "None\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "database_path = 'C:\\\\wildfire\\\\wildfire_detect\\\\FPA_FOD_20170508.sqlite'  # Ensure correct path\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    table_name = 'Fires'\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    print(\"\\nFirst few rows from the Fires table (head):\")\n",
    "    print(df.head())\n",
    "    print(\"\\nInformation about the Fires table (info):\")\n",
    "    print(df.info())\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Error connecting to or querying the database: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Database file not found at {database_path}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vUL86NKF6-B8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRE_SIZE_CLASS\n",
      "B    939376\n",
      "A    666919\n",
      "C    220077\n",
      "D     28427\n",
      "E     14107\n",
      "F      7786\n",
      "G      3773\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in FIRE_SIZE_CLASS:\n",
      "['A' 'B' 'G' 'C' 'D' 'F' 'E']\n"
     ]
    }
   ],
   "source": [
    "print(df['FIRE_SIZE_CLASS'].value_counts())\n",
    "print(\"\\nUnique values in FIRE_SIZE_CLASS:\")\n",
    "print(df['FIRE_SIZE_CLASS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "0    2453403.5\n",
      "1    2453137.5\n",
      "2    2453156.5\n",
      "3    2453184.5\n",
      "4    2453184.5\n",
      "Name: DISCOVERY_DATE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['DISCOVERY_DATE'].dtype)\n",
    "print(df['DISCOVERY_DATE'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DISCOVERY_DATE DISCOVERY_DATE_CONVERTED\n",
      "0       2453403.5               2005-02-02\n",
      "1       2453137.5               2004-05-12\n",
      "2       2453156.5               2004-05-31\n",
      "3       2453184.5               2004-06-28\n",
      "4       2453184.5               2004-06-28\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "def jd_to_datetime(jd):\n",
    "    return pd.to_datetime(jd - 2440587.5, unit='D', origin='1970-01-01')\n",
    "\n",
    "df['DISCOVERY_DATE_CONVERTED'] = df['DISCOVERY_DATE'].apply(jd_to_datetime)\n",
    "\n",
    "print(df[['DISCOVERY_DATE', 'DISCOVERY_DATE_CONVERTED']].head())\n",
    "print(df['DISCOVERY_DATE_CONVERTED'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DISCOVERY_DATE_CONVERTED  DISCOVERY_MONTH\n",
      "0               2005-02-02                2\n",
      "1               2004-05-12                5\n",
      "2               2004-05-31                5\n",
      "3               2004-06-28                6\n",
      "4               2004-06-28                6\n"
     ]
    }
   ],
   "source": [
    "df['DISCOVERY_MONTH'] = df['DISCOVERY_DATE_CONVERTED'].dt.month\n",
    "print(df[['DISCOVERY_DATE_CONVERTED', 'DISCOVERY_MONTH']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DISCOVERY_DATE_CONVERTED  DISCOVERY_MONTH  DISCOVERY_DAYOFWEEK  \\\n",
      "0               2005-02-02                2                    2   \n",
      "1               2004-05-12                5                    2   \n",
      "2               2004-05-31                5                    0   \n",
      "3               2004-06-28                6                    0   \n",
      "4               2004-06-28                6                    0   \n",
      "\n",
      "   DISCOVERY_DAYOFYEAR  DISCOVERY_YEAR  \n",
      "0                   33            2005  \n",
      "1                  133            2004  \n",
      "2                  152            2004  \n",
      "3                  180            2004  \n",
      "4                  180            2004  \n"
     ]
    }
   ],
   "source": [
    "df['DISCOVERY_DAYOFWEEK'] = df['DISCOVERY_DATE_CONVERTED'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['DISCOVERY_DAYOFYEAR'] = df['DISCOVERY_DATE_CONVERTED'].dt.dayofyear\n",
    "df['DISCOVERY_YEAR'] = df['DISCOVERY_DATE_CONVERTED'].dt.year\n",
    "\n",
    "print(df[['DISCOVERY_DATE_CONVERTED', 'DISCOVERY_MONTH', 'DISCOVERY_DAYOFWEEK', 'DISCOVERY_DAYOFYEAR', 'DISCOVERY_YEAR']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1300\n",
      "1    0845\n",
      "2    1921\n",
      "3    1600\n",
      "4    1600\n",
      "Name: DISCOVERY_TIME, dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['DISCOVERY_TIME'].head())\n",
    "print(df['DISCOVERY_TIME'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DISCOVERY_TIME  DISCOVERY_HOUR\n",
      "0           1300           13.00\n",
      "1           0845            8.75\n",
      "2           1921           19.35\n",
      "3           1600           16.00\n",
      "4           1600           16.00\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_to_hours(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        time_str = str(int(time_str)).zfill(4)  # Ensure 4 digits\n",
    "        hours = int(time_str[:2])\n",
    "        minutes = int(time_str[2:])\n",
    "        return hours + minutes / 60.0\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df['DISCOVERY_HOUR'] = df['DISCOVERY_TIME'].apply(time_to_hours)\n",
    "print(df[['DISCOVERY_TIME', 'DISCOVERY_HOUR']].head())\n",
    "print(df['DISCOVERY_HOUR'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LATITUDE   LONGITUDE\n",
      "0  40.036944 -121.005833\n",
      "1  38.933056 -120.404444\n",
      "2  38.984167 -120.735556\n",
      "3  38.559167 -119.913333\n",
      "4  38.559167 -119.933056\n",
      "           LATITUDE     LONGITUDE\n",
      "count  1.880465e+06  1.880465e+06\n",
      "mean   3.678121e+01 -9.570494e+01\n",
      "std    6.139031e+00  1.671694e+01\n",
      "min    1.793972e+01 -1.788026e+02\n",
      "25%    3.281860e+01 -1.103635e+02\n",
      "50%    3.545250e+01 -9.204304e+01\n",
      "75%    4.082720e+01 -8.229760e+01\n",
      "max    7.033060e+01 -6.525694e+01\n",
      "LATITUDE     0\n",
      "LONGITUDE    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['LATITUDE', 'LONGITUDE']].head())\n",
    "print(df[['LATITUDE', 'LONGITUDE']].describe())\n",
    "print(df[['LATITUDE', 'LONGITUDE']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRE_SIZE_CLASS\n",
      "A    0.354656\n",
      "B    0.499545\n",
      "C    0.117033\n",
      "D    0.015117\n",
      "E    0.007502\n",
      "F    0.004140\n",
      "G    0.002006\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['FIRE_SIZE_CLASS'].value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OBJECTID        FOD_ID     FIRE_YEAR  DISCOVERY_DATE  \\\n",
      "count  1.880465e+06  1.880465e+06  1.880465e+06    1.880465e+06   \n",
      "mean   9.402330e+05  5.484020e+07  2.003710e+03    2.453064e+06   \n",
      "min    1.000000e+00  1.000000e+00  1.992000e+03    2.448622e+06   \n",
      "25%    4.701170e+05  5.055000e+05  1.998000e+03    2.451084e+06   \n",
      "50%    9.402330e+05  1.067761e+06  2.004000e+03    2.453178e+06   \n",
      "75%    1.410349e+06  1.910639e+07  2.009000e+03    2.455036e+06   \n",
      "max    1.880465e+06  3.003484e+08  2.015000e+03    2.457388e+06   \n",
      "std    5.428436e+05  1.011963e+08  6.663099e+00    2.434573e+03   \n",
      "\n",
      "       DISCOVERY_DOY  STAT_CAUSE_CODE     CONT_DATE       CONT_DOY  \\\n",
      "count   1.880465e+06     1.880465e+06  9.889340e+05  988934.000000   \n",
      "mean    1.647191e+02     5.979037e+00  2.453238e+06     172.656766   \n",
      "min     1.000000e+00     1.000000e+00  2.448622e+06       1.000000   \n",
      "25%     8.900000e+01     3.000000e+00  2.450701e+06     102.000000   \n",
      "50%     1.640000e+02     5.000000e+00  2.453466e+06     181.000000   \n",
      "75%     2.300000e+02     9.000000e+00  2.455754e+06     232.000000   \n",
      "max     3.660000e+02     1.300000e+01  2.457392e+06     366.000000   \n",
      "std     9.003891e+01     3.483860e+00  2.687548e+03      84.320348   \n",
      "\n",
      "          FIRE_SIZE      LATITUDE     LONGITUDE    OWNER_CODE  \\\n",
      "count  1.880465e+06  1.880465e+06  1.880465e+06  1.880465e+06   \n",
      "mean   7.452016e+01  3.678121e+01 -9.570494e+01  1.059658e+01   \n",
      "min    1.000000e-05  1.793972e+01 -1.788026e+02  0.000000e+00   \n",
      "25%    1.000000e-01  3.281860e+01 -1.103635e+02  8.000000e+00   \n",
      "50%    1.000000e+00  3.545250e+01 -9.204304e+01  1.400000e+01   \n",
      "75%    3.300000e+00  4.082720e+01 -8.229760e+01  1.400000e+01   \n",
      "max    6.069450e+05  7.033060e+01 -6.525694e+01  1.500000e+01   \n",
      "std    2.497598e+03  6.139031e+00  1.671694e+01  4.404662e+00   \n",
      "\n",
      "            DISCOVERY_DATE_CONVERTED  DISCOVERY_MONTH  DISCOVERY_DAYOFWEEK  \\\n",
      "count                        1880465     1.880465e+06         1.880465e+06   \n",
      "mean   2004-02-28 03:46:07.143020416     5.930107e+00         3.046290e+00   \n",
      "min              1992-01-01 00:00:00     1.000000e+00         0.000000e+00   \n",
      "25%              1998-09-28 00:00:00     3.000000e+00         1.000000e+00   \n",
      "50%              2004-06-21 00:00:00     6.000000e+00         3.000000e+00   \n",
      "75%              2009-07-23 00:00:00     8.000000e+00         5.000000e+00   \n",
      "max              2015-12-31 00:00:00     1.200000e+01         6.000000e+00   \n",
      "std                              NaN     2.954900e+00         2.022310e+00   \n",
      "\n",
      "       DISCOVERY_DAYOFYEAR  DISCOVERY_YEAR  DISCOVERY_HOUR  \n",
      "count         1.880465e+06    1.880465e+06   997827.000000  \n",
      "mean          1.647191e+02    2.003710e+03       14.691991  \n",
      "min           1.000000e+00    1.992000e+03        0.000000  \n",
      "25%           8.900000e+01    1.998000e+03       12.666667  \n",
      "50%           1.640000e+02    2.004000e+03       14.950000  \n",
      "75%           2.300000e+02    2.009000e+03       17.133333  \n",
      "max           3.660000e+02    2.015000e+03       23.983333  \n",
      "std           9.003891e+01    6.663096e+00        4.064251  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire_Occurred\n",
      "1    18805\n",
      "0    18805\n",
      "Name: count, dtype: int64\n",
      "    LATITUDE   LONGITUDE  DISCOVERY_MONTH  DISCOVERY_DAYOFWEEK  \\\n",
      "0  30.193750  -94.735410               11                    6   \n",
      "1  43.572998 -129.881881                6                    3   \n",
      "2  44.194731 -141.921666                3                    1   \n",
      "3  35.555000  -79.331700                4                    1   \n",
      "4  33.968742 -116.496225                6                    4   \n",
      "\n",
      "   DISCOVERY_DAYOFYEAR  DISCOVERY_YEAR  DISCOVERY_HOUR  Fire_Occurred  \n",
      "0                  329            2001             NaN              1  \n",
      "1                  351            2013       12.898898              0  \n",
      "2                  210            2011        9.406582              0  \n",
      "3                  104            1998             NaN              1  \n",
      "4                  168            2005       11.983333              1  \n",
      "\n",
      "Shape of the balanced sample DataFrame: (37610, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a sample size for the original fire data (e.g., 1% of the original)\n",
    "sample_fraction = 0.01\n",
    "df_sample_fire = df.sample(frac=sample_fraction, random_state=42).copy()\n",
    "\n",
    "# Number of fire samples in the reduced set\n",
    "num_fire_sample = len(df_sample_fire)\n",
    "\n",
    "# Initialize an empty list to store synthetic no-fire data\n",
    "no_fire_data_sample = []\n",
    "\n",
    "# Generate synthetic no-fire samples equal to the size of the fire sample\n",
    "for _ in range(num_fire_sample):\n",
    "    latitude = np.random.uniform(df_sample_fire['LATITUDE'].min(), df_sample_fire['LATITUDE'].max())\n",
    "    longitude = np.random.uniform(df_sample_fire['LONGITUDE'].min(), df_sample_fire['LONGITUDE'].max())\n",
    "    month = np.random.randint(1, 13)\n",
    "    dayofweek = np.random.randint(0, 7)\n",
    "    dayofyear = np.random.randint(1, 367)\n",
    "    year = np.random.randint(df_sample_fire['DISCOVERY_YEAR'].min(), df_sample_fire['DISCOVERY_YEAR'].max() + 1)\n",
    "    hour = np.random.uniform(0, 24)\n",
    "    fire_occurred = 0  # Label as no fire\n",
    "\n",
    "    no_fire_data_sample.append([latitude, longitude, month, dayofweek, dayofyear, year, hour, fire_occurred])\n",
    "\n",
    "# Create a DataFrame from the synthetic data\n",
    "df_no_fire_sample = pd.DataFrame(no_fire_data_sample, columns=['LATITUDE', 'LONGITUDE', 'DISCOVERY_MONTH', 'DISCOVERY_DAYOFWEEK', 'DISCOVERY_DAYOFYEAR', 'DISCOVERY_YEAR', 'DISCOVERY_HOUR', 'Fire_Occurred'])\n",
    "\n",
    "# Add the 'Fire_Occurred' column to the sampled fire data\n",
    "df_sample_fire['Fire_Occurred'] = 1\n",
    "\n",
    "# Concatenate the sampled fire and synthetic no-fire DataFrames\n",
    "df_balanced_sample = pd.concat([df_sample_fire[['LATITUDE', 'LONGITUDE', 'DISCOVERY_MONTH', 'DISCOVERY_DAYOFWEEK', 'DISCOVERY_DAYOFYEAR', 'DISCOVERY_YEAR', 'DISCOVERY_HOUR', 'Fire_Occurred']], df_no_fire_sample], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined DataFrame\n",
    "df_balanced_sample = df_balanced_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_balanced_sample['Fire_Occurred'].value_counts())\n",
    "print(df_balanced_sample.head())\n",
    "print(f\"\\nShape of the balanced sample DataFrame: {df_balanced_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATITUDE                  0\n",
      "LONGITUDE                 0\n",
      "DISCOVERY_MONTH           0\n",
      "DISCOVERY_DAYOFWEEK       0\n",
      "DISCOVERY_DAYOFYEAR       0\n",
      "DISCOVERY_YEAR            0\n",
      "DISCOVERY_HOUR         8939\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_balanced_sample[['LATITUDE', 'LONGITUDE', 'DISCOVERY_MONTH', 'DISCOVERY_DAYOFWEEK', 'DISCOVERY_DAYOFYEAR', 'DISCOVERY_YEAR', 'DISCOVERY_HOUR']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "median_discovery_hour = df_balanced_sample['DISCOVERY_HOUR'].median()\n",
    "df_balanced_sample['DISCOVERY_HOUR'] = df_balanced_sample['DISCOVERY_HOUR'].fillna(median_discovery_hour)\n",
    "\n",
    "# Verify that missing values are handled\n",
    "print(df_balanced_sample['DISCOVERY_HOUR'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (30088, 7)\n",
      "Shape of X_test: (7522, 7)\n",
      "Shape of y_train: (30088,)\n",
      "Shape of y_test: (7522,)\n",
      "\n",
      "Distribution of target in training set:\n",
      "Fire_Occurred\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribution of target in testing set:\n",
      "Fire_Occurred\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define our features (X) and target (y)\n",
    "X = df_balanced_sample[['LATITUDE', 'LONGITUDE', 'DISCOVERY_MONTH', 'DISCOVERY_DAYOFWEEK', 'DISCOVERY_DAYOFYEAR', 'DISCOVERY_YEAR', 'DISCOVERY_HOUR']]\n",
    "y = df_balanced_sample['Fire_Occurred']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# Print the distribution of the target variable in the training and testing sets\n",
    "print(f\"\\nDistribution of target in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nDistribution of target in testing set:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation ---\n",
      "Accuracy:  0.9747\n",
      "Precision: 0.9702\n",
      "Recall:    0.9795\n",
      "F1-Score:  0.9749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"--- Model Evaluation ---\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
